{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the google rumors\n",
    "dxy_rumors=pd.read_csv('../data/DXY_rumors.csv')\n",
    "google_rumors=pd.read_csv('../data/Google_rumors.csv')\n",
    "label_dict= {}\n",
    "for i in range(len(dxy_rumors)):\n",
    "    label_dict[dxy_rumors.title[i][0:-1]] = dxy_rumors.rumorType[i]\n",
    "label = np.zeros(len(google_rumors),dtype=int)\n",
    "for i in range(len(google_rumors)):\n",
    "     label[i] = label_dict[google_rumors.keyword[i]]\n",
    "google_rumors['label'] = label\n",
    "google_rumors.to_csv('../data/Google_rumors.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `pd.save_csv` not found.\n"
     ]
    }
   ],
   "source": [
    "?pd.save_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "google_rumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "news= pd.read_csv('./data/DXY_news.csv')\n",
    "news['label'] = 3\n",
    "news['data'] = news['title']+news['summary']\n",
    "news= news.drop([\"_id\",\"id\",\"title\",\"pubDate\",\"summary\",\"infoSource\",\"sourceUrl\",\"provinceId\",\"crawlTime\",\"entryWay\",\"infoType\",\"dataInfoState\",\"dataInfoOperator\",\"dataInfoTime\",\"provinceName\",\"createTime\",\"modifyTime\",\"adoptType\",\"body\"], axis=1)\n",
    "#news\n",
    "google_rumor= pd.read_csv('./data/Google_rumors.csv')\n",
    "google_rumor['m_data'] = google_rumor['title']+google_rumor['summary']\n",
    "google_rumor= google_rumor.drop([\"Unnamed: 0\",\"keyword\",\"summary\",\"title\",\"link\",\"visible_link\",\"date\",\"rank\"], axis=1)\n",
    "google_rumor.columns = ['label', 'data']\n",
    "#google_rumor\n",
    "final=pd.concat([google_rumor,news],axis=0)\n",
    "final\n",
    "final.to_csv('./data/much_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/DXY_news.csv does not exist: './data/DXY_news.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-bce6c7dc2ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/DXY_news.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pubDate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"infoSource\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sourceUrl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"provinceId\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"crawlTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"entryWay\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"infoType\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dataInfoState\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dataInfoOperator\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dataInfoTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"provinceName\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"createTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"modifyTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"adoptType\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinydata/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinydata/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinydata/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinydata/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinydata/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/DXY_news.csv does not exist: './data/DXY_news.csv'"
     ]
    }
   ],
   "source": [
    "news= pd.read_csv('./data/DXY_news.csv')\n",
    "news['label'] = 3\n",
    "news['data'] = news['title']+news['summary']\n",
    "news= news.drop([\"_id\",\"id\",\"title\",\"pubDate\",\"summary\",\"infoSource\",\"sourceUrl\",\"provinceId\",\"crawlTime\",\"entryWay\",\"infoType\",\"dataInfoState\",\"dataInfoOperator\",\"dataInfoTime\",\"provinceName\",\"createTime\",\"modifyTime\",\"adoptType\",\"body\"], axis=1)\n",
    "#news\n",
    "google_rumor= pd.read_csv('./data/Google_rumors.csv')\n",
    "google_rumor['m_data'] = google_rumor['title']+google_rumor['summary']\n",
    "google_rumor= google_rumor.drop([\"Unnamed: 0\",\"keyword\",\"summary\",\"title\",\"link\",\"visible_link\",\"date\",\"rank\"], axis=1)\n",
    "google_rumor.columns = ['label', 'data']\n",
    "#google_rumor\n",
    "final=pd.concat([google_rumor,news],axis=0)\n",
    "final\n",
    "final.to_csv('./data/much_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news= pd.read_csv('./data/DXY_news.csv')\n",
    "news['label'] = 3\n",
    "news['data'] = news['title']+news['summary']\n",
    "news= news.drop([\"_id\",\"id\",\"title\",\"pubDate\",\"summary\",\"infoSource\",\"sourceUrl\",\"provinceId\",\"crawlTime\",\"entryWay\",\"infoType\",\"dataInfoState\",\"dataInfoOperator\",\"dataInfoTime\",\"provinceName\",\"createTime\",\"modifyTime\",\"adoptType\",\"body\"], axis=1)\n",
    "#news\n",
    "google_rumor= pd.read_csv('./data/Google_rumors.csv')\n",
    "google_rumor['m_data'] = google_rumor['title']+google_rumor['summary']\n",
    "google_rumor= google_rumor.drop([\"Unnamed: 0\",\"keyword\",\"summary\",\"title\",\"link\",\"visible_link\",\"date\",\"rank\"], axis=1)\n",
    "google_rumor.columns = ['label', 'data']\n",
    "#google_rumor\n",
    "final=pd.concat([google_rumor,news],axis=0)\n",
    "final\n",
    "final.to_csv('./data/much_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "results = []\n",
    "for page_number in range(1,6): \n",
    "    json_str = open('../data/piyao/page_{}.json'.format(page_number),'r').read()\n",
    "    json_page = json.loads(json_str)\n",
    "    json_list = json_page['data']['list']\n",
    "    for item in json_list:\n",
    "        results.append([*item.values()])\n",
    "columns = [*page_json['data']['list'][0].keys()]\n",
    "columns = [x.lower() for x in columns]\n",
    "results = pd.DataFrame(results,columns=columns)\n",
    "results = results.drop([\n",
    " 'docid',\n",
    "#  'title',\n",
    " 'nodeid',\n",
    "#  'pubtime',\n",
    "#  'linkurl',\n",
    " 'abstract',\n",
    "#  'keyword',\n",
    "#  'editor',\n",
    "#  'author',\n",
    " 'islink',\n",
    "#  'sourcename',\n",
    " 'piclinks',\n",
    " 'ismoreimg',\n",
    " 'imgarray',\n",
    " 'subtitle',\n",
    " 'attr',\n",
    " 'm4v',\n",
    " 'tarray',\n",
    " 'uarray',\n",
    " 'allpics',\n",
    " 'introtitle',\n",
    " 'ext1',\n",
    " 'ext2',\n",
    " 'ext3',\n",
    " 'ext4',\n",
    " 'ext5',\n",
    " 'ext6',\n",
    " 'ext7',\n",
    " 'ext8',\n",
    " 'ext9',\n",
    " 'ext10'],axis=1)\n",
    "results.keyword[results.keyword == '快递'] = '谣言'\n",
    "results.keyword[results.keyword == 'None'] = '谣言'\n",
    "results = results[results.keyword != '辟谣']\n",
    "results.keyword[results.keyword == '谣言'] = 0\n",
    "results.keyword[results.keyword == '事实'] = 1\n",
    "results.keyword[results.keyword == '误区'] = 2\n",
    "results = results.drop(results.index[results.keyword.isnull()])\n",
    "results = results.rename(columns={'keyword':'rumorType'})\n",
    "results.to_csv('../data/piyao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pubtime</th>\n",
       "      <th>linkurl</th>\n",
       "      <th>rumorType</th>\n",
       "      <th>editor</th>\n",
       "      <th>author</th>\n",
       "      <th>sourcename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>广西有人3次检测呈阳性？</td>\n",
       "      <td>2020-06-28 10:49:26</td>\n",
       "      <td>http://www.piyao.org.cn/2020-06/28/c_121067970...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>昭平公安</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>蚊蝇可以传播新冠病毒？</td>\n",
       "      <td>2020-06-28 10:49:51</td>\n",
       "      <td>http://www.piyao.org.cn/2020-06/28/c_121067958...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>中国新闻网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>南昌民德路锦江之星酒店发现有俄罗斯人患新冠肺炎？</td>\n",
       "      <td>2020-06-26 11:05:25</td>\n",
       "      <td>http://www.piyao.org.cn/2020-06/26/c_121067743...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>央广网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>市民路过中高风险地区健康码会变色？</td>\n",
       "      <td>2020-06-24 15:44:27</td>\n",
       "      <td>http://www.piyao.org.cn/2020-06/24/c_121067535...</td>\n",
       "      <td>0</td>\n",
       "      <td>冯栋</td>\n",
       "      <td>张璐</td>\n",
       "      <td>新京报</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>上海30天内禁止跨省旅游团？</td>\n",
       "      <td>2020-06-24 16:28:01</td>\n",
       "      <td>http://www.piyao.org.cn/2020-06/24/c_121067536...</td>\n",
       "      <td>0</td>\n",
       "      <td>冯栋</td>\n",
       "      <td>白璐</td>\n",
       "      <td>上海网络辟谣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>中国向菲律宾捐赠20万只口罩？</td>\n",
       "      <td>2020-02-11 23:21:37</td>\n",
       "      <td>http://www.piyao.org.cn/2020-02/11/c_121046411...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>中国驻菲律宾大使馆官网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>疫情致广西防城港市，玉林市博白县、陆川县米粮断供？</td>\n",
       "      <td>2020-02-12 08:42:01</td>\n",
       "      <td>http://www.piyao.org.cn/2020-02/12/c_121047075...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>防城港市市场监管局</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>黑龙江省疫情数据翻倍？</td>\n",
       "      <td>2020-02-11 22:55:06</td>\n",
       "      <td>http://www.piyao.org.cn/2020-02/11/c_121046876...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>东北网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>长沙封城、株洲封外地户口进不了城，一律凭身份证进城？</td>\n",
       "      <td>2020-02-12 08:36:35</td>\n",
       "      <td>http://www.piyao.org.cn/2020-02/12/c_121047076...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>湖南省长沙市交警支队官方微博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>北京西站防控失败致大批外地人涌入？</td>\n",
       "      <td>2020-02-10 14:19:36</td>\n",
       "      <td>http://www.piyao.org.cn/2020-02/10/c_121046792...</td>\n",
       "      <td>0</td>\n",
       "      <td>张智萍</td>\n",
       "      <td>None</td>\n",
       "      <td>北京西站官方微博</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title              pubtime  \\\n",
       "0                  广西有人3次检测呈阳性？  2020-06-28 10:49:26   \n",
       "1                   蚊蝇可以传播新冠病毒？  2020-06-28 10:49:51   \n",
       "2      南昌民德路锦江之星酒店发现有俄罗斯人患新冠肺炎？  2020-06-26 11:05:25   \n",
       "4             市民路过中高风险地区健康码会变色？  2020-06-24 15:44:27   \n",
       "5                上海30天内禁止跨省旅游团？  2020-06-24 16:28:01   \n",
       "..                          ...                  ...   \n",
       "995             中国向菲律宾捐赠20万只口罩？  2020-02-11 23:21:37   \n",
       "996   疫情致广西防城港市，玉林市博白县、陆川县米粮断供？  2020-02-12 08:42:01   \n",
       "997                 黑龙江省疫情数据翻倍？  2020-02-11 22:55:06   \n",
       "998  长沙封城、株洲封外地户口进不了城，一律凭身份证进城？  2020-02-12 08:36:35   \n",
       "999           北京西站防控失败致大批外地人涌入？  2020-02-10 14:19:36   \n",
       "\n",
       "                                               linkurl rumorType editor  \\\n",
       "0    http://www.piyao.org.cn/2020-06/28/c_121067970...         0    张智萍   \n",
       "1    http://www.piyao.org.cn/2020-06/28/c_121067958...         0    张智萍   \n",
       "2    http://www.piyao.org.cn/2020-06/26/c_121067743...         0    张智萍   \n",
       "4    http://www.piyao.org.cn/2020-06/24/c_121067535...         0     冯栋   \n",
       "5    http://www.piyao.org.cn/2020-06/24/c_121067536...         0     冯栋   \n",
       "..                                                 ...       ...    ...   \n",
       "995  http://www.piyao.org.cn/2020-02/11/c_121046411...         0    张智萍   \n",
       "996  http://www.piyao.org.cn/2020-02/12/c_121047075...         0    张智萍   \n",
       "997  http://www.piyao.org.cn/2020-02/11/c_121046876...         0    张智萍   \n",
       "998  http://www.piyao.org.cn/2020-02/12/c_121047076...         0    张智萍   \n",
       "999  http://www.piyao.org.cn/2020-02/10/c_121046792...         0    张智萍   \n",
       "\n",
       "    author      sourcename  \n",
       "0     None            昭平公安  \n",
       "1     None           中国新闻网  \n",
       "2     None             央广网  \n",
       "4       张璐             新京报  \n",
       "5       白璐          上海网络辟谣  \n",
       "..     ...             ...  \n",
       "995   None     中国驻菲律宾大使馆官网  \n",
       "996   None       防城港市市场监管局  \n",
       "997   None             东北网  \n",
       "998   None  湖南省长沙市交警支队官方微博  \n",
       "999   None        北京西站官方微博  \n",
       "\n",
       "[948 rows x 7 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'keyword'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
